# Simple Web Crawler

â€‹	*Program ini digunakan untuk mengekstrak data dari sebuah website. Untuk* source code *lengkap, sila klik [di sini](https://github.com/Ibara99/Simple-Web-Crawling).*

# Pengantar

> Ucapan terima kasih kepada Bapak [Mulaab, S.Si., M.Kom.](https://forlap.ristekdikti.go.id/dosen/detail/RTA5QTg4RjctMjBEQy00QThELUI4REYtREQ5ODAzMzU0MjUz) selaku Dosen Pembimbing kami

> Nama 			: Ibnu Asro Putra
>
> NRP			: 160411100023
>
> Mata kuliah 		: Penambangan dan Pencarian Web - 2019
>
> Jurusan			: Teknik Informatika
>
> Perguruan Tinggi	: Universitas Trunojoyo Madura

# Environment 

*Program ini dijalankan menggunakan:*

- Bahasa Python, dengan library:
  - BeautifulSoup4 (install menggunakan pip)
  - requests (install menggunakan pip)
  - SQLite3 (library bawaan python)
  - csv  (library bawaan python)
  - numpy (install menggunakan pip)
  - scipy (install menggunakan pip)
  - scikit-learn (install menggunakan pip, perlu untuk install numpy dan scipy terlebih dulu)
  - Scikit-fuzzy (install menggunakan pip, perlu untuk install numpy dan scipy terlebih dulu)
- Website target : [Jurnal Online](https://garuda.ristekdikti.go.id))

> Jika anda memutuskan untuk meng-update data, maka Program **hanya** bisa dijalankan menggunakan Internet, atau program akan error

> Setiap kali program dijalankan, akan muncul file baru bernama `test.db`, dan beberapa file `csv`. File tersebut merupakan file database serta output program.
